{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import check_random_state\n",
    "\n",
    "\n",
    "# Maze state is represented as a 2-element NumPy array: (Y, X). Increasing Y is South.\n",
    "\n",
    "# Possible actions, expressed as (delta-y, delta-x).\n",
    "maze_actions = {\n",
    "    'N': np.array([0, -1, 0]),\n",
    "    'S': np.array([0, 1, 0]),\n",
    "    'E': np.array([0, 0, 1]),\n",
    "    'W': np.array([0, 0, -1]),\n",
    "    'K': np.array([0, 0, 0])\n",
    "}\n",
    "\n",
    "def parse_topology(topology):\n",
    "    return np.array([[list(col) for col in row] for row in topology])\n",
    "\n",
    "\n",
    "class Maze(object):\n",
    "    \"\"\"\n",
    "    Simple wrapper around a NumPy 3D array to handle flattened indexing and staying in bounds.\n",
    "    \"\"\"\n",
    "    def __init__(self, topology):\n",
    "        self.topology = parse_topology(topology)\n",
    "        self.flat_topology = self.topology.ravel()\n",
    "        self.shape = self.topology.shape\n",
    "\n",
    "    def in_bounds_flat(self, position):\n",
    "        return 0 <= position < np.product(self.shape)\n",
    "\n",
    "    def in_bounds_unflat(self, position):\n",
    "        return 0 <= position[0] < self.shape[0] and 0 <= position[1] < self.shape[1] and 0 <= position[2] < self.shape[2]\n",
    "\n",
    "    def get_flat(self, position):\n",
    "        if not self.in_bounds_flat(position):\n",
    "            raise IndexError(\"Position out of bounds: {}\".format(position))\n",
    "        return self.flat_topology[position]\n",
    "\n",
    "    def get_unflat(self, position):\n",
    "        if not self.in_bounds_unflat(position):\n",
    "            raise IndexError(\"Position out of bounds: {}\".format(position))\n",
    "        return self.topology[tuple(position)]\n",
    "\n",
    "    def flatten_index(self, index_tuple):\n",
    "        return np.ravel_multi_index(index_tuple, self.shape)\n",
    "\n",
    "    def unflatten_index(self, flattened_index):\n",
    "        return np.unravel_index(flattened_index, self.shape)\n",
    "\n",
    "    def flat_positions_containing(self, x):\n",
    "        return list(np.nonzero(self.flat_topology == x)[0])\n",
    "\n",
    "    def flat_positions_not_containing(self, x):\n",
    "        return list(np.nonzero(self.flat_topology != x)[0])\n",
    "    \n",
    "    def flat_change(self, position, element):\n",
    "        if not self.in_bounds_flat(position):\n",
    "            raise IndexError(\"Position out of bounds: {}\".format(position))\n",
    "        self.flat_topology[position] = element\n",
    "        self.topology[tuple(self.unflatten_index(position))] = element\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n\\n'.join('\\n'.join(''.join(row) for row in level) for level in self.topology.tolist())\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Maze({})'.format(repr(self.topology.tolist()))\n",
    "\n",
    "#***********************************************************************\n",
    "def move_avoiding_walls(maze, position, action, climb):\n",
    "    \"\"\"\n",
    "    Return the new position after moving, and the event that happened ('hit-wall' or 'moved').\n",
    "\n",
    "    Works with the position and action as a (row, column) array.\n",
    "    \"\"\"\n",
    "    # Compute new position\n",
    "    new_position = position + action\n",
    "\n",
    "    # Compute collisions with walls, including implicit walls at the ends of the world.\n",
    "    if not maze.in_bounds_unflat(new_position) or maze.get_unflat(new_position) == '#':\n",
    "        return position, 'hit-wall'\n",
    "\n",
    "    # Go to the stairs\n",
    "    if maze.get_unflat(new_position) == '%':\n",
    "        flat_new_position = climb[maze.flatten_index(new_position)]\n",
    "        new_position = maze.unflatten_index(flat_new_position)\n",
    "        return new_position, 'stair'\n",
    "\n",
    "    # GO to people and back\n",
    "    if maze.get_unflat(new_position) == 'a':\n",
    "        return position, 'runinto-people'\n",
    "\n",
    "    return new_position, 'moved'\n",
    "\n",
    "\n",
    "def move_adversary(maze, position, action):\n",
    "    \"\"\"\n",
    "    Return the new position of one adversary.\n",
    "    \n",
    "    Works with the positon and action as a (row, column) array.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_position = position + action\n",
    "    \n",
    "    # Compute collisions with walls, including implicit walls at the ends of the world.\n",
    "    if not maze.in_bounds_unflat(new_position) or maze.get_unflat(new_position) == '#' or maze.get_unflat(new_position) == '%':\n",
    "        return position\n",
    "    \n",
    "    # GO to people and back\n",
    "    if maze.get_unflat(new_position) == 'P':\n",
    "        return position\n",
    "    \n",
    "    return new_position\n",
    "\n",
    "#***********************************************************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GridWorld(object):\n",
    "    \"\"\"\n",
    "    A simple task in a maze: get to the goal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    maze : list of strings or lists\n",
    "        maze topology (see below)\n",
    "\n",
    "    rewards: dict of string to number. default: {'*': 10}.\n",
    "        Rewards obtained by being in a maze grid with the specified contents,\n",
    "        or experiencing the specified event (either 'hit-wall' or 'moved'). The\n",
    "        contributions of content reward and event reward are summed. For\n",
    "        example, you might specify a cost for moving by passing\n",
    "        rewards={'*': 10, 'moved': -1}.\n",
    "\n",
    "    terminal_markers: sequence of chars, default '*'\n",
    "        A grid cell containing any of these markers will be considered a\n",
    "        \"terminal\" state.\n",
    "\n",
    "    action_error_prob: float\n",
    "        With this probability, the requested action is ignored and a random\n",
    "        action is chosen instead.\n",
    "\n",
    "    random_state: None, int, or RandomState object\n",
    "        For repeatable experiments, you can pass a random state here. See\n",
    "        http://scikit-learn.org/stable/modules/generated/sklearn.utils.check_random_state.html\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "    Maze topology is expressed textually. Key:\n",
    "     '#': wall\n",
    "     '.': open (really, anything that's not '#')\n",
    "     '*': goal\n",
    "     'o': origin\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, maze, num_advs=3, rewards={'*': 10}, terminal_markers='*', action_error_prob=0, random_state=None, directions=\"NSEWK\"):\n",
    "\n",
    "        self.maze = Maze(maze) if not isinstance(maze, Maze) else maze\n",
    "        self.rewards = rewards\n",
    "        self.terminal_markers = terminal_markers\n",
    "        self.action_error_prob = action_error_prob\n",
    "        self.random_state = check_random_state(random_state)\n",
    "        self.num_advs = num_advs\n",
    "        \n",
    "        # find all available position\n",
    "        self.available_state = self.maze.flat_positions_containing('.')\n",
    "                \n",
    "        # randomly choose position of adversary\n",
    "        self.adversaries_position = np.random.choice(self.available_state, replace=False, size=self.num_advs)\n",
    "        \n",
    "        # find stairs\n",
    "        self.stairs = self.maze.flat_positions_containing('%')\n",
    "        \n",
    "        # dict to upstair or downstair\n",
    "        self.climb = {self.stairs[0]:self.stairs[1], self.stairs[1]: self.stairs[0]}\n",
    "\n",
    "        self.actions = [maze_actions[direction] for direction in directions]\n",
    "        self.num_actions = len(self.actions)\n",
    "        self.state = None\n",
    "        self.reset()\n",
    "        self.num_states = self.maze.shape[0] * self.maze.shape[1] * self.maze.shape[2]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'GridWorld(maze={maze!r}, rewards={rewards}, terminal_markers={terminal_markers}, action_error_prob={action_error_prob})'.format(**self.__dict__)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the position of agent and adversaries to a starting position (an 'o'), chosen at random.\n",
    "        \"\"\"\n",
    "        options = self.maze.flat_positions_containing('o')\n",
    "        self.state = options[self.random_state.choice(len(options))]\n",
    "        self.adversaries_position = np.random.choice(self.available_state, replace=False, size=self.num_advs)\n",
    "\n",
    "    def is_terminal(self, state):\n",
    "        \"\"\"Check if the given state is a terminal state.\"\"\"\n",
    "        return self.maze.get_flat(state) in self.terminal_markers\n",
    "\n",
    "    def observe(self):\n",
    "        \"\"\"\n",
    "        Return the current state and position of adversaries as integers.\n",
    "\n",
    "        The state and position is the index into the flattened maze.\n",
    "        \"\"\"\n",
    "        return self.state, self.adversaries_position\n",
    "    \n",
    "    def add_adv_maze(self):\n",
    "        \"\"\"\n",
    "        Return the gridworld with adversary and agent\n",
    "        \"\"\"\n",
    "        tmp = Maze(mall.maze.topology)\n",
    "        for adver_p in self.adversaries_position:\n",
    "            tmp.flat_change(adver_p, 'a')\n",
    "            \n",
    "        tmp.flat_change(self.state, 'I')\n",
    "        return tmp\n",
    "        \n",
    "    \n",
    "    def visualize(self):\n",
    "        \"\"\"\n",
    "        Print the gridworld with adversary and agent\n",
    "        \"\"\"\n",
    "        tmp = self.add_adv_maze()\n",
    "        print str(tmp)\n",
    "        \n",
    "\n",
    "    def perform_action(self, action_idx):\n",
    "        \"\"\"Perform an action (specified by index), yielding a new state and reward.\"\"\"\n",
    "        # In the absorbing end state, nothing does anything.\n",
    "        if self.is_terminal(self.state):\n",
    "            return self.observe(), 0\n",
    "        \n",
    "        # move adversary first\n",
    "        for idx in xrange(self.num_advs):\n",
    "            action_idx_a = self.random_state.choice(self.num_actions)\n",
    "            action = self.actions[action_idx_a]\n",
    "            new_position = move_adversary(self.add_adv_maze(),\n",
    "                                          self.maze.unflatten_index(self.adversaries_position[idx]),\n",
    "                                          action)\n",
    "            self.adversaries_position[idx] = self.maze.flatten_index(new_position)\n",
    "\n",
    "        if self.action_error_prob and self.random_state.rand() < self.action_error_prob:\n",
    "            action_idx = self.random_state.choice(self.num_actions)\n",
    "        action = self.actions[action_idx]\n",
    "        new_state_tuple, result = move_avoiding_walls(self.add_adv_maze(), \n",
    "                                                      self.maze.unflatten_index(self.state), \n",
    "                                                      action, self.climb)\n",
    "        self.state = self.maze.flatten_index(new_state_tuple)\n",
    "\n",
    "        reward = self.rewards.get(self.maze.get_flat(self.state), 0) + self.rewards.get(result, 0)\n",
    "        return self.observe(), reward\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def as_mdp(self):\n",
    "        transition_probabilities = np.zeros((self.num_states, self.num_actions, self.num_states))\n",
    "        rewards = np.zeros((self.num_states, self.num_actions, self.num_states))\n",
    "        action_rewards = np.zeros((self.num_states, self.num_actions))\n",
    "        destination_rewards = np.zeros(self.num_states)\n",
    "\n",
    "        for state in range(self.num_states):\n",
    "            destination_rewards[state] = self.rewards.get(self.maze.get_flat(state), 0)\n",
    "\n",
    "        is_terminal_state = np.zeros(self.num_states, dtype=np.bool)\n",
    "\n",
    "        for state in range(self.num_states):\n",
    "            if self.is_terminal(state):\n",
    "                is_terminal_state[state] = True\n",
    "                transition_probabilities[state, :, state] = 1.\n",
    "            else:\n",
    "                for action in range(self.num_actions):\n",
    "                    new_state_tuple, result = move_avoiding_walls(self.maze, self.maze.unflatten_index(state), self.actions[action])\n",
    "                    new_state = self.maze.flatten_index(new_state_tuple)\n",
    "                    transition_probabilities[state, action, new_state] = 1.\n",
    "                    action_rewards[state, action] = self.rewards.get(result, 0)\n",
    "\n",
    "        # Now account for action noise.\n",
    "        transitions_given_random_action = transition_probabilities.mean(axis=1, keepdims=True)\n",
    "        transition_probabilities *= (1 - self.action_error_prob)\n",
    "        transition_probabilities += self.action_error_prob * transitions_given_random_action\n",
    "\n",
    "        rewards_given_random_action = action_rewards.mean(axis=1, keepdims=True)\n",
    "        action_rewards = (1 - self.action_error_prob) * action_rewards + self.action_error_prob * rewards_given_random_action\n",
    "        rewards = action_rewards[:, :, None] + destination_rewards[None, None, :]\n",
    "        rewards[is_terminal_state] = 0\n",
    "\n",
    "        return transition_probabilities, rewards\n",
    "\n",
    "    def get_max_reward(self):\n",
    "        transition_probabilities, rewards = self.as_mdp()\n",
    "        return rewards.max()\n",
    "\n",
    "    ### Old API, where terminal states were None.\n",
    "\n",
    "    def observe_old(self):\n",
    "        return None if self.is_terminal(self.state) else self.state\n",
    "\n",
    "    def perform_action_old(self, action_idx):\n",
    "        new_state, reward = self.perform_action(action_idx)\n",
    "        if self.is_terminal(new_state):\n",
    "            return None, reward\n",
    "        else:\n",
    "            return new_state, reward\n",
    "\n",
    "\n",
    "    samples = {\n",
    "        'trivial': [\n",
    "            '###',\n",
    "            '#o#',\n",
    "            '#.#',\n",
    "            '#*#',\n",
    "            '###'],\n",
    "\n",
    "        'larger': [\n",
    "            '#########',\n",
    "            '#..#....#',\n",
    "            '#..#..#.#',\n",
    "            '#..#..#.#',\n",
    "            '#..#.##.#',\n",
    "            '#....*#.#',\n",
    "            '#######.#',\n",
    "            '#o......#',\n",
    "            '#########'],\n",
    "\n",
    "        'two level': [\n",
    "            [\n",
    "            '#########',\n",
    "            '#......%#',\n",
    "            '#.......#',\n",
    "            '#..#....#',\n",
    "            '#..#....#',\n",
    "            '#.......#',\n",
    "            '##......#',\n",
    "            '#o......#',\n",
    "            '#########'],\n",
    "            [\n",
    "            '#########',\n",
    "            '#......%#',\n",
    "            '#.......#',\n",
    "            '#..#....#',\n",
    "            '#..#....#',\n",
    "            '#.......#',\n",
    "            '##......#',\n",
    "            '#*......#',\n",
    "            '#########']\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def construct_cliff_task(width, height, goal_reward=50, move_reward=-1, cliff_reward=-100, **kw):\n",
    "    \"\"\"\n",
    "    Construct a 'cliff' task, a GridWorld with a \"cliff\" between the start and\n",
    "    goal. Falling off the cliff gives a large negative reward and ends the\n",
    "    episode.\n",
    "\n",
    "    Any other parameters, like action_error_prob, are passed on to the\n",
    "    GridWorld constructor.\n",
    "    \"\"\"\n",
    "\n",
    "    maze = ['.' * width] * (height - 1)  # middle empty region\n",
    "    maze.append('o' + 'X' * (width - 2) + '*') # bottom goal row\n",
    "\n",
    "    rewards = {\n",
    "        '*': goal_reward,\n",
    "        'moved': move_reward,\n",
    "        'hit-wall': move_reward,\n",
    "        'X': cliff_reward\n",
    "    }\n",
    "\n",
    "    return GridWorld(maze, rewards=rewards, terminal_markers='*X', **kw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mall_grid = GridWorld.samples[\"two level\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mall = GridWorld(maze = mall_grid, num_advs=3, \n",
    "                 rewards = {\"moved\":-1, \"*\":10, \"hit-wall\":-10, \"runinto-people\":-10, \"stair\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 34, 129,  14], dtype=int64)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mall.adversaries_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "#......%#\n",
      "#.a.....#\n",
      "#..#....#\n",
      "#..#....#\n",
      "#.......#\n",
      "##......#\n",
      "#I.a....#\n",
      "#########\n",
      "\n",
      "#########\n",
      "#......%#\n",
      "#.......#\n",
      "#..#....#\n",
      "#..#....#\n",
      "#.a.....#\n",
      "##......#\n",
      "#*......#\n",
      "#########\n",
      "(0, 2, 2)\n",
      "(0, 7, 3)\n",
      "(1, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "mall.reset()\n",
    "mall.visualize()\n",
    "for i in mall.adversaries_position:\n",
    "    print mall.maze.unflatten_index(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "print mall.maze.unflatten_index(mall.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n",
      "[0 0 1]\n",
      "[ 0 -1  0]\n",
      "[ 29  67 119]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((64, array([ 29,  67, 119], dtype=int64)), -10)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mall.perform_action(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3, 2)\n",
      "(0, 7, 4)\n",
      "(1, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "for i in mall.adversaries_position:\n",
    "    print mall.maze.unflatten_index(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "#......%#\n",
      "#.......#\n",
      "#.a#....#\n",
      "#..#....#\n",
      "#.......#\n",
      "##......#\n",
      "#I..a...#\n",
      "#########\n",
      "\n",
      "#########\n",
      "#......%#\n",
      "#.......#\n",
      "#..#....#\n",
      "#.a#....#\n",
      "#.......#\n",
      "##......#\n",
      "#*......#\n",
      "#########\n"
     ]
    }
   ],
   "source": [
    "mall.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
